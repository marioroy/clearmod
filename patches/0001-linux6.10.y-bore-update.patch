Unofficial modifications to the BORE patch.

1. Improve BORE on RT, including benefit for non-RT and running RR tasks.

Mitigate micro-pauses/skipped-frames in Unigine Superposition.

The pauses can be seen noticeably at low base_slice on a many-core machine,
with more than 32 CPU threads. More so running BORE-RT.

2. What is this about?

I checked via borestat that BORE does not have activity running primesieve
with SCHED_FIFO or SCHED_RR policy. But, the random stutters persists.

$ chrt -f 1 primesieve --threads=4 1e12
$ chrt -r 1 primesieve --threads=4 1e12

The Superposition stutters occur when pipewire/wireplumber spikes in top.
On my system, /usr/bin/{pipewire, pipewire-pulse, and wireplumber} run with
the real-time SCHED_RR policy. Ensure that BORE does not affect SCHED_FIFO
or SCHED_RR tasks by checking rt_policy, defined in kernel/sched/sched.h.

static inline int rt_policy(int policy)
{
        return policy == SCHED_FIFO || policy == SCHED_RR;
}

3. After results.

Superposition runs smoothly and unaffected by pipewire spikes in top.


diff -uarp a/kernel/sched/bore.c b/kernel/sched/bore.c
--- a/kernel/sched/bore.c
+++ b/kernel/sched/bore.c
@@ -63,7 +63,8 @@ static inline u8 effective_prio(struct t
 }
 
 void update_burst_score(struct sched_entity *se) {
-	if (!entity_is_task(se)) return;
+	if (!entity_is_task(se) || rt_policy(task_of(se)->policy))
+		return;
 	struct task_struct *p = task_of(se);
 	u8 prev_prio = effective_prio(p);
 
@@ -104,6 +105,8 @@ inline void restart_burst(struct sched_e
 }
 
 void restart_burst_rescale_deadline(struct sched_entity *se) {
+	if (rt_policy(task_of(se)->policy))
+		return;
 	s64 vscaled, wremain, vremain = se->deadline - se->vruntime;
 	struct task_struct *p = task_of(se);
 	u8 prev_prio = effective_prio(p);
@@ -125,6 +128,7 @@ static void reset_task_weights_bore(void
 
 	write_lock_irq(&tasklist_lock);
 	for_each_process(task) {
+		if (rt_policy(task->policy)) continue;
 		rq = task_rq(task);
 		rq_lock_irqsave(rq, &rf);
 		reweight_task_by_prio(task, effective_prio(task));
@@ -252,7 +256,7 @@ static inline u8 inherit_burst_tg(struct
 
 void sched_clone_bore(
 	struct task_struct *p, struct task_struct *parent, u64 clone_flags) {
-	if (!task_is_bore_eligible(p)) return;
+	if (!task_is_bore_eligible(p) || rt_policy(p->policy)) return;
 
 	u64 now = ktime_get_ns();
 	read_lock(&tasklist_lock);
diff -uarp a/kernel/sched/fair.c b/kernel/sched/fair.c
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -1202,8 +1202,10 @@ static void update_curr(struct cfs_rq *c
 		return;
 
 #ifdef CONFIG_SCHED_BORE
-	curr->burst_time += delta_exec;
-	update_burst_penalty(curr);
+	if (!rt_policy(task_of(curr)->policy)) {
+		curr->burst_time += delta_exec;
+		update_burst_penalty(curr);
+	}
 #endif // CONFIG_SCHED_BORE
 	curr->vruntime += calc_delta_fair(delta_exec, curr);
 	update_deadline(cfs_rq, curr);
@@ -5317,7 +5319,7 @@ place_entity(struct cfs_rq *cfs_rq, stru
 		return;
 	}
 #ifdef CONFIG_SCHED_BORE
-	else if (likely(sched_bore))
+	else if (likely(sched_bore) && !rt_policy(task_of(se)->policy))
 		vslice >>= !!(flags & sched_deadline_boost_mask);
 	else
 #endif // CONFIG_SCHED_BORE
@@ -6915,7 +6917,7 @@ static void dequeue_task_fair(struct rq
 
 	util_est_dequeue(&rq->cfs, p);
 #ifdef CONFIG_SCHED_BORE
-	if (task_sleep) {
+	if (task_sleep && !rt_policy(task_of(se)->policy)) {
 		cfs_rq = cfs_rq_of(se);
 		if (cfs_rq->curr == se)
 			update_curr(cfs_rq);
